{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25d28666-8ccb-4ca0-bb58-87ab9ecfa2aa",
   "metadata": {},
   "source": [
    "# 230968080\n",
    "\n",
    "Week 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b95cf6e6-23cd-4194-b1ad-89fbee21df2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "local_zip = '/home/mca/Desktop/230968080/hin-eng.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall()\n",
    "zip_ref.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "220cedb3-e4ef-438f-9394-aae1dca03767",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-26 15:09:11.630830: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-26 15:09:11.655349: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-26 15:09:12.017976: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 3116\n",
      "Number of unique input tokens: 91\n",
      "Number of unique output tokens: 72\n",
      "Max sequence length for inputs: 121\n",
      "Max sequence length for outputs: 109\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# --- Hyperparameters ---\n",
    "batch_size = 64\n",
    "epochs = 50 # For a good result, 100 is better, but 50 is faster for demonstration.\n",
    "latent_dim = 256 # Dimensionality of the encoding space.\n",
    "num_samples = 10000 # Number of samples to train on.\n",
    "data_path = \"hin.txt\" \n",
    "\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "\n",
    "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.read().split(\"\\n\")\n",
    "\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    try:\n",
    "        target_text, input_text, _ = line.split(\"\\t\")\n",
    "\n",
    "        target_text = \"\\t\" + target_text + \"\\n\"\n",
    "        \n",
    "        input_texts.append(input_text)\n",
    "        target_texts.append(target_text)\n",
    "        \n",
    "        for char in input_text:\n",
    "            if char not in input_characters:\n",
    "                input_characters.add(char)\n",
    "        for char in target_text:\n",
    "            if char not in target_characters:\n",
    "                target_characters.add(char)\n",
    "    except ValueError:\n",
    "        continue\n",
    "\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "print(\"Number of samples:\", len(input_texts))\n",
    "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
    "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
    "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
    "print(\"Max sequence length for outputs:\", max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b6ba3ce-8e17-4b95-8013-3393ffb7e97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data vectorization complete.\n"
     ]
    }
   ],
   "source": [
    "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\"\n",
    ")\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
    ")\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
    ")\n",
    "\n",
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
    "    encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
    "    for t, char in enumerate(target_text):\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
    "        if t > 0:\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
    "    decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
    "    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0\n",
    "    \n",
    "print(\"Data vectorization complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c7a7f3c-0f1a-45aa-868c-178f5efde289",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-26 15:09:15.212668: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-26 15:09:15.227180: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-26 15:09:15.227301: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-26 15:09:15.228282: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-26 15:09:15.228358: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-26 15:09:15.228405: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-26 15:09:15.540650: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-26 15:09:15.540756: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-26 15:09:15.540807: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-26 15:09:15.540857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9756 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- LSTM Model Summary ---\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, None, 91)]           0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, None, 72)]           0         []                            \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 [(None, 256),                356352    ['input_1[0][0]']             \n",
      "                              (None, 256),                                                        \n",
      "                              (None, 256)]                                                        \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               [(None, None, 256),          336896    ['input_2[0][0]',             \n",
      "                              (None, 256),                           'lstm[0][1]',                \n",
      "                              (None, 256)]                           'lstm[0][2]']                \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, None, 72)             18504     ['lstm_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 711752 (2.72 MB)\n",
      "Trainable params: 711752 (2.72 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Encoder\n",
    "encoder_inputs_lstm = keras.Input(shape=(None, num_encoder_tokens))\n",
    "encoder_lstm = keras.layers.LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs_lstm, state_h_lstm, state_c_lstm = encoder_lstm(encoder_inputs_lstm)\n",
    "encoder_states_lstm = [state_h_lstm, state_c_lstm]\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs_lstm = keras.Input(shape=(None, num_decoder_tokens))\n",
    "decoder_lstm = keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs_lstm, _, _ = decoder_lstm(decoder_inputs_lstm, initial_state=encoder_states_lstm)\n",
    "decoder_dense_lstm = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\")\n",
    "decoder_outputs_lstm = decoder_dense_lstm(decoder_outputs_lstm)\n",
    "\n",
    "# full model\n",
    "model_lstm = keras.Model([encoder_inputs_lstm, decoder_inputs_lstm], decoder_outputs_lstm)\n",
    "\n",
    "model_lstm.compile(\n",
    "    optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "print(\"--- LSTM Model Summary ---\")\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9182bfc6-1de5-4b1b-bd4a-f6ceee8d3c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- GRU Model Summary ---\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)        [(None, None, 91)]           0         []                            \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)        [(None, None, 72)]           0         []                            \n",
      "                                                                                                  \n",
      " gru (GRU)                   [(None, 256),                268032    ['input_3[0][0]']             \n",
      "                              (None, 256)]                                                        \n",
      "                                                                                                  \n",
      " gru_1 (GRU)                 [(None, None, 256),          253440    ['input_4[0][0]',             \n",
      "                              (None, 256)]                           'gru[0][1]']                 \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, None, 72)             18504     ['gru_1[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 539976 (2.06 MB)\n",
      "Trainable params: 539976 (2.06 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# GRU \n",
    "\n",
    "# Encoder\n",
    "encoder_inputs_gru = keras.Input(shape=(None, num_encoder_tokens))\n",
    "encoder_gru = keras.layers.GRU(latent_dim, return_state=True)\n",
    "encoder_outputs_gru, state_h_gru = encoder_gru(encoder_inputs_gru)\n",
    "encoder_states_gru = [state_h_gru] # GRU only has one state\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs_gru = keras.Input(shape=(None, num_decoder_tokens))\n",
    "decoder_gru = keras.layers.GRU(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs_gru, _ = decoder_gru(decoder_inputs_gru, initial_state=encoder_states_gru)\n",
    "decoder_dense_gru = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\")\n",
    "decoder_outputs_gru = decoder_dense_gru(decoder_outputs_gru)\n",
    "\n",
    "# Define the full model\n",
    "model_gru = keras.Model([encoder_inputs_gru, decoder_inputs_gru], decoder_outputs_gru)\n",
    "\n",
    "model_gru.compile(\n",
    "    optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "print(\"\\n--- GRU Model Summary ---\")\n",
    "model_gru.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99919b48-6f15-45ff-873e-8241a8f909e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training LSTM Model ---\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-26 15:09:21.818166: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-26 15:09:21.898466: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-26 15:09:21.900144: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f14c002e570 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-26 15:09:21.900159: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2025-09-26 15:09:21.903179: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-26 15:09:21.955928: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 3s 25ms/step - loss: 1.2592 - accuracy: 0.7704 - val_loss: 1.8996 - val_accuracy: 0.6254\n",
      "Epoch 2/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.9850 - accuracy: 0.7887 - val_loss: 1.7190 - val_accuracy: 0.6275\n",
      "Epoch 3/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.8388 - accuracy: 0.7930 - val_loss: 1.4725 - val_accuracy: 0.6281\n",
      "Epoch 4/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.8052 - accuracy: 0.7932 - val_loss: 1.6597 - val_accuracy: 0.6281\n",
      "Epoch 5/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.7811 - accuracy: 0.7928 - val_loss: 1.4588 - val_accuracy: 0.6304\n",
      "Epoch 6/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.7655 - accuracy: 0.7934 - val_loss: 1.4904 - val_accuracy: 0.6286\n",
      "Epoch 7/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.7445 - accuracy: 0.7941 - val_loss: 1.5323 - val_accuracy: 0.6218\n",
      "Epoch 8/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.7320 - accuracy: 0.7969 - val_loss: 1.4533 - val_accuracy: 0.6288\n",
      "Epoch 9/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.7252 - accuracy: 0.7992 - val_loss: 1.4675 - val_accuracy: 0.6224\n",
      "Epoch 10/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.7098 - accuracy: 0.8016 - val_loss: 1.4309 - val_accuracy: 0.6271\n",
      "Epoch 11/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.6850 - accuracy: 0.8067 - val_loss: 1.3873 - val_accuracy: 0.6316\n",
      "Epoch 12/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.6855 - accuracy: 0.8100 - val_loss: 1.2561 - val_accuracy: 0.6403\n",
      "Epoch 13/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.6417 - accuracy: 0.8187 - val_loss: 1.2294 - val_accuracy: 0.6471\n",
      "Epoch 14/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.6406 - accuracy: 0.8238 - val_loss: 1.1687 - val_accuracy: 0.6699\n",
      "Epoch 15/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.6072 - accuracy: 0.8288 - val_loss: 1.1579 - val_accuracy: 0.6796\n",
      "Epoch 16/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.5949 - accuracy: 0.8310 - val_loss: 1.1629 - val_accuracy: 0.6652\n",
      "Epoch 17/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.5839 - accuracy: 0.8329 - val_loss: 1.1575 - val_accuracy: 0.6697\n",
      "Epoch 18/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.5824 - accuracy: 0.8337 - val_loss: 1.1102 - val_accuracy: 0.6796\n",
      "Epoch 19/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.5674 - accuracy: 0.8359 - val_loss: 1.0906 - val_accuracy: 0.6853\n",
      "Epoch 20/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.5624 - accuracy: 0.8375 - val_loss: 1.0937 - val_accuracy: 0.6794\n",
      "Epoch 21/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.5563 - accuracy: 0.8390 - val_loss: 1.0717 - val_accuracy: 0.6915\n",
      "Epoch 22/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.5513 - accuracy: 0.8403 - val_loss: 1.0754 - val_accuracy: 0.6865\n",
      "Epoch 23/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.5460 - accuracy: 0.8412 - val_loss: 1.0714 - val_accuracy: 0.6869\n",
      "Epoch 24/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.5414 - accuracy: 0.8427 - val_loss: 1.0638 - val_accuracy: 0.6874\n",
      "Epoch 25/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.5369 - accuracy: 0.8435 - val_loss: 1.0649 - val_accuracy: 0.6865\n",
      "Epoch 26/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.5331 - accuracy: 0.8443 - val_loss: 1.0585 - val_accuracy: 0.6918\n",
      "Epoch 27/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.5288 - accuracy: 0.8457 - val_loss: 1.0566 - val_accuracy: 0.6927\n",
      "Epoch 28/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.5245 - accuracy: 0.8469 - val_loss: 1.0342 - val_accuracy: 0.6971\n",
      "Epoch 29/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.5211 - accuracy: 0.8475 - val_loss: 1.0328 - val_accuracy: 0.6983\n",
      "Epoch 30/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.5179 - accuracy: 0.8485 - val_loss: 1.0441 - val_accuracy: 0.6938\n",
      "Epoch 31/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.5140 - accuracy: 0.8494 - val_loss: 0.9987 - val_accuracy: 0.7096\n",
      "Epoch 32/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.5109 - accuracy: 0.8501 - val_loss: 1.0410 - val_accuracy: 0.6952\n",
      "Epoch 33/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.5074 - accuracy: 0.8509 - val_loss: 1.0046 - val_accuracy: 0.7058\n",
      "Epoch 34/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.5043 - accuracy: 0.8520 - val_loss: 1.0014 - val_accuracy: 0.7069\n",
      "Epoch 35/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.5015 - accuracy: 0.8534 - val_loss: 0.9926 - val_accuracy: 0.7086\n",
      "Epoch 36/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.4981 - accuracy: 0.8540 - val_loss: 1.0498 - val_accuracy: 0.6950\n",
      "Epoch 37/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.4952 - accuracy: 0.8550 - val_loss: 1.0130 - val_accuracy: 0.7072\n",
      "Epoch 38/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.4929 - accuracy: 0.8554 - val_loss: 0.9933 - val_accuracy: 0.7106\n",
      "Epoch 39/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.4899 - accuracy: 0.8564 - val_loss: 0.9935 - val_accuracy: 0.7077\n",
      "Epoch 40/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.4872 - accuracy: 0.8570 - val_loss: 0.9835 - val_accuracy: 0.7127\n",
      "Epoch 41/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.4843 - accuracy: 0.8581 - val_loss: 0.9729 - val_accuracy: 0.7162\n",
      "Epoch 42/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.4819 - accuracy: 0.8588 - val_loss: 0.9680 - val_accuracy: 0.7177\n",
      "Epoch 43/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.4793 - accuracy: 0.8599 - val_loss: 0.9778 - val_accuracy: 0.7139\n",
      "Epoch 44/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.4761 - accuracy: 0.8601 - val_loss: 0.9705 - val_accuracy: 0.7160\n",
      "Epoch 45/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.4741 - accuracy: 0.8603 - val_loss: 0.9770 - val_accuracy: 0.7156\n",
      "Epoch 46/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.4723 - accuracy: 0.8609 - val_loss: 0.9821 - val_accuracy: 0.7141\n",
      "Epoch 47/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.4685 - accuracy: 0.8620 - val_loss: 0.9690 - val_accuracy: 0.7175\n",
      "Epoch 48/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.4670 - accuracy: 0.8625 - val_loss: 0.9535 - val_accuracy: 0.7229\n",
      "Epoch 49/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.4638 - accuracy: 0.8637 - val_loss: 0.9717 - val_accuracy: 0.7175\n",
      "Epoch 50/50\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.4626 - accuracy: 0.8640 - val_loss: 0.9612 - val_accuracy: 0.7203\n",
      "\n",
      "--- Training GRU Model ---\n",
      "Epoch 1/50\n",
      "39/39 [==============================] - 2s 21ms/step - loss: 1.3376 - accuracy: 0.7700 - val_loss: 2.1191 - val_accuracy: 0.6254\n",
      "Epoch 2/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.9465 - accuracy: 0.7907 - val_loss: 1.5255 - val_accuracy: 0.6254\n",
      "Epoch 3/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.8832 - accuracy: 0.7902 - val_loss: 1.5797 - val_accuracy: 0.6250\n",
      "Epoch 4/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.8111 - accuracy: 0.7870 - val_loss: 1.3991 - val_accuracy: 0.6064\n",
      "Epoch 5/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.7583 - accuracy: 0.7914 - val_loss: 1.3690 - val_accuracy: 0.6337\n",
      "Epoch 6/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.7189 - accuracy: 0.8019 - val_loss: 1.3241 - val_accuracy: 0.6262\n",
      "Epoch 7/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.6836 - accuracy: 0.8102 - val_loss: 1.2309 - val_accuracy: 0.6550\n",
      "Epoch 8/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.6500 - accuracy: 0.8184 - val_loss: 1.2362 - val_accuracy: 0.6438\n",
      "Epoch 9/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.6731 - accuracy: 0.8235 - val_loss: 1.1553 - val_accuracy: 0.6793\n",
      "Epoch 10/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.6092 - accuracy: 0.8307 - val_loss: 1.1422 - val_accuracy: 0.6750\n",
      "Epoch 11/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.5924 - accuracy: 0.8323 - val_loss: 1.1029 - val_accuracy: 0.6818\n",
      "Epoch 12/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.5774 - accuracy: 0.8341 - val_loss: 1.1125 - val_accuracy: 0.6848\n",
      "Epoch 13/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.6180 - accuracy: 0.8282 - val_loss: 1.1137 - val_accuracy: 0.6900\n",
      "Epoch 14/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.5618 - accuracy: 0.8381 - val_loss: 1.0982 - val_accuracy: 0.6881\n",
      "Epoch 15/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.5558 - accuracy: 0.8380 - val_loss: 1.0516 - val_accuracy: 0.7030\n",
      "Epoch 16/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.5497 - accuracy: 0.8393 - val_loss: 1.0556 - val_accuracy: 0.6943\n",
      "Epoch 17/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.5444 - accuracy: 0.8404 - val_loss: 1.0366 - val_accuracy: 0.6891\n",
      "Epoch 18/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.5395 - accuracy: 0.8420 - val_loss: 1.0455 - val_accuracy: 0.6978\n",
      "Epoch 19/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.5355 - accuracy: 0.8431 - val_loss: 1.0419 - val_accuracy: 0.6931\n",
      "Epoch 20/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.5311 - accuracy: 0.8441 - val_loss: 1.0210 - val_accuracy: 0.7044\n",
      "Epoch 21/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.5276 - accuracy: 0.8448 - val_loss: 1.0203 - val_accuracy: 0.7028\n",
      "Epoch 22/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.5241 - accuracy: 0.8455 - val_loss: 1.0395 - val_accuracy: 0.6907\n",
      "Epoch 23/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.5208 - accuracy: 0.8468 - val_loss: 1.0220 - val_accuracy: 0.6966\n",
      "Epoch 24/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.5182 - accuracy: 0.8473 - val_loss: 0.9965 - val_accuracy: 0.7062\n",
      "Epoch 25/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.5148 - accuracy: 0.8485 - val_loss: 0.9982 - val_accuracy: 0.7099\n",
      "Epoch 26/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.7057 - accuracy: 0.8292 - val_loss: 0.9896 - val_accuracy: 0.7086\n",
      "Epoch 27/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.5099 - accuracy: 0.8497 - val_loss: 0.9724 - val_accuracy: 0.7129\n",
      "Epoch 28/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.5072 - accuracy: 0.8503 - val_loss: 0.9900 - val_accuracy: 0.7065\n",
      "Epoch 29/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.5051 - accuracy: 0.8506 - val_loss: 0.9834 - val_accuracy: 0.7062\n",
      "Epoch 30/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.5023 - accuracy: 0.8516 - val_loss: 0.9835 - val_accuracy: 0.7054\n",
      "Epoch 31/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.4993 - accuracy: 0.8524 - val_loss: 0.9699 - val_accuracy: 0.7127\n",
      "Epoch 32/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.4968 - accuracy: 0.8529 - val_loss: 0.9537 - val_accuracy: 0.7179\n",
      "Epoch 33/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.4939 - accuracy: 0.8538 - val_loss: 0.9669 - val_accuracy: 0.7126\n",
      "Epoch 34/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.4914 - accuracy: 0.8543 - val_loss: 0.9575 - val_accuracy: 0.7172\n",
      "Epoch 35/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.4886 - accuracy: 0.8554 - val_loss: 0.9607 - val_accuracy: 0.7143\n",
      "Epoch 36/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.4858 - accuracy: 0.8562 - val_loss: 0.9769 - val_accuracy: 0.7101\n",
      "Epoch 37/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.4834 - accuracy: 0.8571 - val_loss: 0.9520 - val_accuracy: 0.7150\n",
      "Epoch 38/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.4806 - accuracy: 0.8578 - val_loss: 0.9557 - val_accuracy: 0.7171\n",
      "Epoch 39/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.4782 - accuracy: 0.8581 - val_loss: 0.9474 - val_accuracy: 0.7186\n",
      "Epoch 40/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.4759 - accuracy: 0.8592 - val_loss: 0.9450 - val_accuracy: 0.7174\n",
      "Epoch 41/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.4736 - accuracy: 0.8598 - val_loss: 0.9362 - val_accuracy: 0.7250\n",
      "Epoch 42/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.4712 - accuracy: 0.8600 - val_loss: 0.9540 - val_accuracy: 0.7181\n",
      "Epoch 43/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.4695 - accuracy: 0.8609 - val_loss: 0.9274 - val_accuracy: 0.7254\n",
      "Epoch 44/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.4667 - accuracy: 0.8617 - val_loss: 0.9466 - val_accuracy: 0.7191\n",
      "Epoch 45/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.4647 - accuracy: 0.8619 - val_loss: 0.9445 - val_accuracy: 0.7177\n",
      "Epoch 46/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.4624 - accuracy: 0.8625 - val_loss: 0.9227 - val_accuracy: 0.7248\n",
      "Epoch 47/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.4602 - accuracy: 0.8630 - val_loss: 0.9067 - val_accuracy: 0.7318\n",
      "Epoch 48/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.4578 - accuracy: 0.8639 - val_loss: 0.9309 - val_accuracy: 0.7221\n",
      "Epoch 49/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.4561 - accuracy: 0.8638 - val_loss: 0.9416 - val_accuracy: 0.7183\n",
      "Epoch 50/50\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.4537 - accuracy: 0.8647 - val_loss: 0.9321 - val_accuracy: 0.7224\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Training LSTM Model ---\")\n",
    "history_lstm = model_lstm.fit(\n",
    "    [encoder_input_data, decoder_input_data],\n",
    "    decoder_target_data,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2,\n",
    ")\n",
    "\n",
    "print(\"\\n--- Training GRU Model ---\")\n",
    "history_gru = model_gru.fit(\n",
    "    [encoder_input_data, decoder_input_data],\n",
    "    decoder_target_data,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04aa8446-86ed-4139-8d5a-3509f82ff7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create Reverse Token Dictionaries for Decoding ---\n",
    "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ab4bbf4-620e-4bb8-94aa-73f9a5599c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inference_models(model_type, trained_model):\n",
    "    # --- ENCODER ---\n",
    "    encoder_inputs = trained_model.input[0]\n",
    "    if model_type == 'lstm':\n",
    "        _, state_h_enc, state_c_enc = trained_model.layers[2].output\n",
    "        encoder_states = [state_h_enc, state_c_enc]\n",
    "        encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
    "    else: # gru\n",
    "        _, state_h_enc = trained_model.layers[2].output\n",
    "        # FIX 1: The GRU encoder model now returns the state tensor directly.\n",
    "        encoder_model = keras.Model(encoder_inputs, state_h_enc)\n",
    "\n",
    "    # --- DECODER ---\n",
    "    decoder_inputs = trained_model.input[1]\n",
    "    decoder_state_input_h = keras.Input(shape=(latent_dim,))\n",
    "    \n",
    "    if model_type == 'lstm':\n",
    "        decoder_state_input_c = keras.Input(shape=(latent_dim,))\n",
    "        decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "        decoder_layer = trained_model.layers[3]\n",
    "        decoder_outputs, state_h_dec, state_c_dec = decoder_layer(\n",
    "            decoder_inputs, initial_state=decoder_states_inputs\n",
    "        )\n",
    "        decoder_states = [state_h_dec, state_c_dec]\n",
    "        decoder_dense = trained_model.layers[4]\n",
    "        decoder_outputs = decoder_dense(decoder_outputs)\n",
    "        decoder_model = keras.Model(\n",
    "            [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n",
    "        )\n",
    "    else: # gru\n",
    "        # FIX 2: The decoder model now accepts the state tensor directly.\n",
    "        decoder_layer = trained_model.layers[3]\n",
    "        decoder_outputs, state_h_dec = decoder_layer(\n",
    "            decoder_inputs, initial_state=decoder_state_input_h\n",
    "        )\n",
    "        decoder_states = [state_h_dec]\n",
    "        decoder_dense = trained_model.layers[4]\n",
    "        decoder_outputs = decoder_dense(decoder_outputs)\n",
    "        decoder_model = keras.Model(\n",
    "            [decoder_inputs, decoder_state_input_h], [decoder_outputs] + decoder_states\n",
    "        )\n",
    "    \n",
    "    return encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1529acc2-aadf-49aa-8b7c-db031cb38aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq, encoder_model, decoder_model, model_type):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    target_seq[0, 0, target_token_index[\"\\t\"]] = 1.0\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "    while not stop_condition:\n",
    "        if model_type == 'lstm':\n",
    "            # LSTM logic remains the same (it expects a list of states)\n",
    "            output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "            states_value = [h, c]\n",
    "        else: # gru\n",
    "            # FIX 3: Pass the target_seq and the single state tensor in a list\n",
    "            # and update the state directly without wrapping it in a list.\n",
    "            output_tokens, h = decoder_model.predict([target_seq, states_value])\n",
    "            states_value = h\n",
    "            \n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n",
    "            stop_condition = True\n",
    "\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.0\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4afd3b21-2129-4f6a-91fa-a04ad5c2facc",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model_lstm, decoder_model_lstm = create_inference_models('lstm', model_lstm)\n",
    "encoder_model_gru, decoder_model_gru = create_inference_models('gru', model_gru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "035cfa77-9656-4cb5-a412-82ac71f5c077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Comparison ---\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "--------------------------------------------------\n",
      "Input (Hindi): चियर्स!\n",
      "Target (English): Cheers!\n",
      "LSTM Translation: I wan the prone the prook.\n",
      "GRU Translation: I wan the prowe the sead.\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "--------------------------------------------------\n",
      "Input (Hindi): अंदर आ जाओ।\n",
      "Target (English): Come in.\n",
      "LSTM Translation: I wan the prone the prook.\n",
      "GRU Translation: I wan the prowe the sead.\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "--------------------------------------------------\n",
      "Input (Hindi): मौज करना।\n",
      "Target (English): Have fun.\n",
      "LSTM Translation: I wan the prone the prook.\n",
      "GRU Translation: I wan the prowe the sead.\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "--------------------------------------------------\n",
      "Input (Hindi): पंछी उड़ते हैं।\n",
      "Target (English): Birds fly.\n",
      "LSTM Translation: I wan the prone the prook.\n",
      "GRU Translation: I wan the prowe the sead.\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "--------------------------------------------------\n",
      "Input (Hindi): मैं थक गया हूँ।\n",
      "Target (English): I'm tired.\n",
      "LSTM Translation: I wan the prone the prook.\n",
      "GRU Translation: I wan the prowe the sead.\n"
     ]
    }
   ],
   "source": [
    "# Test and Compare \n",
    "print(\"\\n--- Model Comparison ---\")\n",
    "for seq_index in [10, 20, 30, 40, 50]: # Picking a few random samples\n",
    "    input_seq = encoder_input_data[seq_index : seq_index + 1]\n",
    "    \n",
    "    decoded_sentence_lstm = decode_sequence(input_seq, encoder_model_lstm, decoder_model_lstm, 'lstm')\n",
    "    \n",
    "    decoded_sentence_gru = decode_sequence(input_seq, encoder_model_gru, decoder_model_gru, 'gru')\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "    print(\"Input (Hindi):\", input_texts[seq_index])\n",
    "    print(\"Target (English):\", target_texts[seq_index].strip())\n",
    "    print(\"LSTM Translation:\", decoded_sentence_lstm.strip())\n",
    "    print(\"GRU Translation:\", decoded_sentence_gru.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd39cbbf-11db-4039-8d06-2edf645c8812",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
