{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0a664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637d2eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset/\n",
    "    train/\n",
    "        class1/\n",
    "        class2/\n",
    "    val/\n",
    "        class1/\n",
    "        class2/\n",
    "    test/\n",
    "        class1/\n",
    "        class2/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7d5b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Option A — If dataset ALREADY has train / val / test folders\n",
    "data_dir = \"/content/dataset\"\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir + \"/train\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMG_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir + \"/val\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMG_SIZE\n",
    ")\n",
    "\n",
    "test_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir + \"/test\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMG_SIZE\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4890193",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Option B — If dataset has ONLY one folder → auto-split\n",
    "data_dir = \"/content/dataset\"\n",
    "\n",
    "train_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "val_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33be2784",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1)\n",
    "])\n",
    "\n",
    "preprocess_layer = layers.Rescaling(1/255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcd5e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(224, 224, 3)),\n",
    "\n",
    "    data_augmentation,\n",
    "    preprocess_layer,\n",
    "\n",
    "    layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "    layers.MaxPooling2D(),\n",
    "\n",
    "    layers.Conv2D(64, 3, activation=\"relu\"),\n",
    "    layers.MaxPooling2D(),\n",
    "\n",
    "    layers.Conv2D(128, 3, activation=\"relu\"),\n",
    "    layers.MaxPooling2D(),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dense(train_ds.cardinality().numpy(), activation=\"softmax\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799c64af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dff33a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history[\"accuracy\"], label=\"train\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"val\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history[\"loss\"], label=\"train\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val\")\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023e81d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_ds)\n",
    "print(\"Test Accuracy:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b8d6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get true labels\n",
    "y_true = np.concatenate([y for x, y in test_ds], axis=0)\n",
    "\n",
    "# Get predictions\n",
    "y_pred_probs = model.predict(test_ds)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3ad8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "img_path = \"/content/sample.jpg\"\n",
    "img = image.load_img(img_path, target_size=IMG_SIZE)\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, 0)  # create batch axis\n",
    "img_array = img_array / 255.0\n",
    "\n",
    "pred = model.predict(img_array)\n",
    "class_index = pred.argmax()\n",
    "print(\"Predicted class:\", train_ds.class_names[class_index])\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
